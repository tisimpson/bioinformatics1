{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='darkblue'>Week 6 - Lab Notebook - Working with Biological Databases</font>\n",
    "\n",
    "- October 2023\n",
    "- https://https://github.com/tisimpson/bioinformatics1\n",
    "- ian.simpson@ed.ac.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='darkblue'>Introduction</font>\n",
    "In this computing lab we are going to be making some plots and tables. We've included code to make simple plots using matplotlib and nicer looking tables using PrettyTable in the various notebooks in the previous weeks so you can borrow code from there and modify it as needed.\n",
    "\n",
    "In this computing lab you are going to try to find answers to biological questions using data that you query/download/analyse from some of the websites we introduced last week. You can follow the code in the week5&6 notebooks and make changes to them and use some time to tackle some of the challenges/problems at the end of the notebooks. We've summarised these below.\n",
    "\n",
    "##### <font color='darkblue'>Learning Outcomes</font>\n",
    "After this tutorial you should be comfortable with:\n",
    "• Identifying a selection of databases likely to contain data you need in a research project\n",
    "• Navigating and creating custom queries to extract and download data from these databases\n",
    "• Processing & Filtering data to use in summary analysis and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='darkblue'>Activity 1 – Genomic Data</font>\n",
    "\n",
    "Refer to the [bio1_week5&6_part1.ipynb](https://github.com/tisimpson/bioinformatics1/blob/main/labs/notebooks/bio1_week5%266_part1.ipynb) notebook for this activity. If you have already worked through this notebook skip to number 4.\n",
    "\n",
    "Go to the [NCBI download page](https://www.ncbi.nlm.nih.gov/home/download/) and click \"download by FTP\". This will lead to a directory tree. Click \"gene\", then \"data\" and either fetch the complete \"gene_info.gz\" file or better navigate further into the \"GENE_INFO\" directory and from the directories inside there find the gene_info file for the individual species (a much smaller file). For example the human file is found [here](https://ftp.ncbi.nlm.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz). Have a look at the README file in this directory for detailed information about the content and structure of the files.\n",
    "\n",
    "- Human (Homo sapiens)\n",
    "- Mouse (Mus musculus)\n",
    "- Rat (Rattus Norvegicus)\n",
    "- Fruitfly (Drosophila melanogaster)\n",
    "- Yeast (Saccharomyces cerevisiae)\n",
    "  \n",
    "1. Using these data files create plots for each species to show:\n",
    "   - Total Number of Genes by Species (in one plot)\n",
    "   - Number of Genes by gene_type (you can try individual plots and stacked histograms)\n",
    "2.  For the same species find the total size of their genomes (in nucleotides) (you can find this by finding the genomes in the genome browsing table at [NCBI Genomes](https://www.ncbi.nlm.nih.gov/datasets/genomes/?taxon=overview)).\n",
    "3. Now create a plot where you normalise the number of genes by genome size and plot this for all the species on one plot, what do you think of the outcome?\n",
    "4. (optional) Can you perform the same analysis as 1-3 above, but for the number of unique transcripts in each genome? You are going to want to work with the feature table file which summarises the information for genomic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 1.1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the 5 genome files from .../data/genomes\n",
    "# and store them in a list called genomes\n",
    "\n",
    "#read the gene_info files into Pandas data frames\n",
    "human_df = pd.read_csv('../data/genomes/Homo_sapiens.gene_info.gz', compression='gzip', header=0, sep='\\t')\n",
    "mouse_df = pd.read_csv('../data/genomes/Mus_musculus.gene_info.gz', compression='gzip', header=0, sep='\\t')\n",
    "rat_df = pd.read_csv('../data/genomes/Rattus_norvegicus.gene_info.gz', compression='gzip', header=0, sep='\\t')\n",
    "fruitfly_df = pd.read_csv('../data/genomes/Drosophila_melanogaster.gene_info.gz', compression='gzip', header=0, sep='\\t')\n",
    "yeast_df = pd.read_csv('../data/genomes/Saccharomyces_cerevisiae.gene_info.gz', compression='gzip', header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 1.1\n",
    "\n",
    "# use seaborn to plot gene count by species\n",
    "import seaborn as sns\n",
    "genomes = {'Homo sapiens':human_df,'Mus musculus':mouse_df,'Rattus norvegicus':rat_df,'Drosophila melanogaster':fruitfly_df,'Saccharomyces cerevisiae':yeast_df}\n",
    "\n",
    "# create a list of tuples containing species name and gene count\n",
    "gene_counts = [(species, len(genomes[species].value_counts('Symbol'))) for species in genomes]\n",
    "\n",
    "# create a dataframe from the list of tuples\n",
    "df_gene_counts = pd.DataFrame(gene_counts, columns=['Species', 'Gene Count'])\n",
    "\n",
    "# plot the gene count by species using a barplot\n",
    "ax = sns.barplot(x='Species', y='Gene Count', data=df_gene_counts)\n",
    "ax.set_xticks(ax.get_xticks(), labels=df_gene_counts['Species'],rotation=30,ha='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create a stack barplot of the gene count by gene type_of_gene\n",
    "# first create a list of tuples containing species name, gene type, and gene count\n",
    "# exclude any entries for which gene_type is either unknown, other, or biological-region\n",
    "gene_counts = [(species, gene_type, len(genomes[species][genomes[species]['type_of_gene'] == gene_type])) for species in genomes for gene_type in genomes[species]['type_of_gene'].unique() if gene_type not in ['unknown', 'other', 'biological-region']]\n",
    "\n",
    "# create a dataframe from the list of tuples\n",
    "df_gene_counts = pd.DataFrame(gene_counts, columns=['Species', 'Gene Type', 'Gene Count'])\n",
    "\n",
    "# plot this using a stacked barplot with species on the x-axis and gene count on the y-axis rotated 30 degrees\n",
    "ax = sns.barplot(x='Species', y='Gene Count', hue='Gene Type', data=df_gene_counts)\n",
    "ax.tick_params(axis='x', labelrotation = 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actitivy 1.2\n",
    "\n",
    "# ul.request.urlretrieve('https://ftp.ncbi.nlm.nih.gov/genomes/GENOME_REPORTS/overview.txt','../data/genomes/genomes.txt')\n",
    "\n",
    "#build the genomes report dataframe\n",
    "genomes_df = pd.read_csv('../data/genomes/genomes.txt',header=0,sep='\\t',low_memory=False)\n",
    "\n",
    "# find the rows matching our species of interest\n",
    "species = ['Homo sapiens','Mus musculus','Rattus norvegicus','Drosophila melanogaster','Saccharomyces cerevisiae']\n",
    "\n",
    "# find the rows in genomes_df matching our species\n",
    "species_rows = genomes_df[genomes_df['#Organism/Name'].isin(species)]\n",
    "# print the rows\n",
    "species_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 1.3\n",
    "\n",
    "gene_merge = pd.merge(df_gene_counts,species_rows,left_on='Species',right_on='#Organism/Name')\n",
    "\n",
    "# divide 'Gene Count' column by 'Size (Mb)' column and add to dataframe\n",
    "gene_merge['Gene Density'] = gene_merge['Gene Count'] / pd.to_numeric(gene_merge['Size (Mb)'])\n",
    "\n",
    "# plot this using a stacked barplot with species on the x-axis and gene count on the y-axis rotated 30 degrees\n",
    "ax = sns.barplot(x='Species', y='Gene Density', hue='Gene Type', data=gene_merge)\n",
    "ax.tick_params(axis='x', labelrotation = 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 1.4\n",
    "\n",
    "import urllib as ul\n",
    "\n",
    "# number of unique transcripts per species\n",
    "# normalise by genome size\n",
    "\n",
    "ref_locations = ul.request.urlretrieve('https://ftp.ncbi.nlm.nih.gov/genomes/refseq/assembly_summary_refseq.txt','../data/genomes/refseq_locs.txt');\n",
    "\n",
    "# compress the file with gzip compression\n",
    "import gzip\n",
    "with open('../data/genomes/refseq_locs.txt', 'rb') as f_in:\n",
    "    with gzip.open('../data/genomes/refseq_locs.txt.gz', 'wb') as f_out:\n",
    "        f_out.writelines(f_in)\n",
    "        \n",
    "# remove the uncompressed file\n",
    "import os\n",
    "os.remove('../data/genomes/refseq_locs.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_locations = pd.read_csv('../data/genomes/refseq_locs.txt.gz',compression='gzip',sep='\\t',header=1,low_memory=False)\n",
    "\n",
    "df_ref_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the rows matching our species of interest\n",
    "\n",
    "# best searched by taxonmic ids\n",
    "\n",
    "tax_ids = [9606,10090,10116,7227,4932]\n",
    "\n",
    "# find the rows in genomes_df matching our species and return the organism_name and taxid columns\n",
    "# this is a bit fiddly\n",
    "\n",
    "species_rows = df_ref_locations[\n",
    "    df_ref_locations['species_taxid'].isin(tax_ids) &\n",
    "    ((df_ref_locations['refseq_category'] == 'reference genome')\n",
    "    | (df_ref_locations['refseq_category'] == 'representative genome'))\n",
    "][['organism_name','taxid','ftp_path']]\n",
    "\n",
    "# print the rows\n",
    "species_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the assembly report files for each species and name the files after the species\n",
    "for index, row in species_rows.iterrows():\n",
    "    ul.request.urlretrieve(row['ftp_path'] + '/' + row['ftp_path'].split('/')[-1] + '_feature_table.txt.gz','../data/genomes/' + row['organism_name'].replace(' ','_') + '_feature_table.txt.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the feature tables into dataframes\n",
    "\n",
    "def feature_types(df_features):\n",
    "    featureCounts = df_features['# feature'].value_counts().to_frame(name='counts')\n",
    "    featureCounts = featureCounts.rename_axis('feature_type').reset_index()\n",
    "    #rename the columns\n",
    "    featureCounts.columns = ['feature_type','counts']\n",
    "    return featureCounts\n",
    "\n",
    "\n",
    "#create a dataframe containing the feature counts for each feature type\n",
    "feature_counts = {}\n",
    "for index, row in species_rows.iterrows():\n",
    "    feature_counts[row['organism_name']] = feature_types(pd.read_csv('../data/genomes/' + row['organism_name'].replace(' ','_') + '_feature_table.txt.gz',sep='\\t',header=0,compression='gzip',low_memory=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the species to each row\n",
    "for species in feature_counts:\n",
    "    feature_counts[species] = feature_counts[species].assign(Species=species)\n",
    "    \n",
    "# concatenate the dataframes\n",
    "df_feature_counts = pd.concat(feature_counts)\n",
    "\n",
    "# plot the feature counts by species using a stacked barplot\n",
    "ax = sns.barplot(x='Species', y='counts', hue='feature_type', data=df_feature_counts)\n",
    "ax.set_ylabel('Feature Count')\n",
    "ax.tick_params(axis='x', labelrotation = 40)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now correct for genome size using the gene_merge dataframe\n",
    "# first merge the feature_counts dataframe with the gene_merge dataframe\n",
    "\n",
    "df_feature_counts = pd.merge(df_feature_counts,gene_merge,left_on='Species',right_on='Species')\n",
    "\n",
    "# divide the feature counts by the genome size\n",
    "df_feature_counts['counts'] = df_feature_counts['counts'] / pd.to_numeric(df_feature_counts['Size (Mb)'])\n",
    "\n",
    "# plot the feature counts by species using a stacked barplot\n",
    "ax = sns.barplot(x='Species', y='counts', hue='feature_type', data=df_feature_counts)\n",
    "ax.set_ylabel('Feature Density')\n",
    "ax.tick_params(axis='x', labelrotation = 40)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='darkblue'>Activity 2 – Pathways and Protein-Protein Interaction Networks</font>\n",
    "\n",
    "Refer to the [bio1_week5&6_part2.ipynb](https://github.com/tisimpson/bioinformatics1/blob/main/labs/notebooks/bio1_week5%266_part2.ipynb) notebook for this activity.\n",
    "\n",
    "1. Go to the [KEGG pathway database](https://www.genome.jp/kegg/pathway.html) and download a list of human genes that are part of the “Cell adhesion molecules\". In the search make sure you restrict it to humans only. This is actually pretty tricky so if you get stuck the list can be found [here](https://www.genome.jp/entry/pathway+hsa04514) and [here](https://www.genome.jp/dbget-bin/get_linkdb?-t+genes+path:hsa04514).\n",
    "\n",
    "We're going to look for evidence of interactions between these proteins using the StringDB database which we will look at in more detail in a couple of weeks when we learn about networks and their analysis. In the week 8 lab we're going to learn how to do the whole process computationally.\n",
    "\n",
    "2. Parse that list (the numeric part of the hsa : <NUMBER> identifier in the list is in fact the NCBI Entrez GeneID accession) and then go to [StringDB](https://string-db.org) click \"Search\" and then on the left-hand side \"Multiple Proteins\" and paste in the search list being sure to select human. Use the tabs to find the information to answer the following questions.\n",
    "3. How many interactions are there? How many orphans (proteins with no interactions) are there?\n",
    "4. What is the average number of interactions that any protein in the list has with other members (this is called the mean degree)?\n",
    "5. Now repeat 2-4 above several times, each time applying these different restrictions using the \"Settings\" tab with the following active interaction data sources:\n",
    "   - Experimental, Co-expression, and Co-occurence\n",
    "   - Experimental only\n",
    "What difference do these changes make to the number of interactions and the mean degree? Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB** The 3 activities below are much easier to gather via Python coding. This week (look also at the notebooks we will study on Friday) you will see how programmatic access greatly facilitates many of the tasks we would like to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 2.1\n",
    "\n",
    "# Fetching KEGG pathway data\n",
    "\n",
    "# Now we will use this file which contains the full pathway details including the gene names.\n",
    "\n",
    "# open the file\n",
    "cam_file = open('../data/pathways/cams.txt','r')\n",
    "\n",
    "# create an empty dataframe with two columns\n",
    "cam_df = pd.DataFrame(columns=['gene_id','gene_symbol','description'])\n",
    "\n",
    "# set a flag for our parser\n",
    "flag=0\n",
    "\n",
    "# work through the text file one line at a time\n",
    "for line in cam_file:\n",
    "    # find the start of the gene entries\n",
    "    if 'GENE' in line:\n",
    "        # add the first gene tp the dataframe\n",
    "        gene_id,remain = line.strip('GENE').strip().split('  ')\n",
    "        gene_symbol,description = remain.split(';')\n",
    "        # add a new row to the dataframe containing the gene_id and description\n",
    "        cam_df = pd.concat([cam_df,pd.DataFrame([[gene_id,gene_symbol,description]],columns=['gene_id','gene_symbol','description'])],ignore_index=True)\n",
    "        # set the flag to 1, we are in the gene section of the file\n",
    "        flag = 1\n",
    "    # stop when we reach the end of the section and escape the file\n",
    "    elif 'REFERENCE' in line:\n",
    "        break\n",
    "    # continue adding the genes to the dataframe\n",
    "    elif flag == 1:\n",
    "        try:\n",
    "            gene_id,remain = line.strip('GENE').strip().split('  ')\n",
    "            gene_symbol,description = remain.split(';')\n",
    "            # add the gene to the dataframe\n",
    "            cam_df = pd.concat([cam_df,pd.DataFrame([[gene_id,gene_symbol,description]],columns=['gene_id','gene_symbol','description'])],ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "# close the file\n",
    "cam_file.close()\n",
    "\n",
    "# view the file\n",
    "cam_df.head()\n",
    "\n",
    "# you now have the gene_ids (NCBI EntrezIDs for the genes in the pathway)\n",
    "print('The Cell Adhesion Molecules pathway has '+str(cam_df.shape[0])+' genes in it.\\n')\n",
    "\n",
    "gene_symbols = cam_df['gene_symbol'].to_numpy()\n",
    "\n",
    "# show the gene_symbols\n",
    "print(gene_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 2.2 and 2.3\n",
    "\n",
    "# create a concatenated list of entrezIDs as strings\n",
    "# note we are taking integer gene_ids from the 'gene_id' column of the dataframe we generated above then using\n",
    "# the map function to convert each one into a string. The join function then concatenates them using the '%0D' string\n",
    "# to stitch them all together. This string will be used to help us build the API query URL.\n",
    "entrezIDs = '%0D'.join(map(str,cam_df['gene_id']))\n",
    "\n",
    "# pass the list of EntrezIDs to the String-DB API return the String-IDs\n",
    "# we first form the query url using the 'get_string_ids' API function which takes a list of identifiers and\n",
    "# converts them into the internal String-DB accession IDs. This massively speeds up the search and allows us to\n",
    "# search for more than 10 at once which is an API restriction for other API functions if String-DB internal accessions \n",
    "# aren't used.\n",
    "query_url = 'https://string-db.org/api/tsv-no-header/get_string_ids?identifiers='+entrezIDs+'&species=9606&format=only-ids'\n",
    "\n",
    "# use the urllib library to retrieve the String-DB internal IDs\n",
    "result = ul.request.urlopen(query_url).read().decode('utf-8')\n",
    "\n",
    "# now we want to query String-DB to retrieve interactions from this list of String-DB IDs\n",
    "# we create a concatenated list of stringdbIDs in much the same way as above for the Entrez Gene IDs\n",
    "stringdbIDs = '%0D'.join(result.splitlines())\n",
    "\n",
    "# again we build the query for interactions using the String-DB IDs\n",
    "query_url = 'https://string-db.org/api/tsv/network?identifiers='+stringdbIDs+'&species=9606'\n",
    "\n",
    "# again using urllib to retrieve the interactions these are returned in a standard tab delimied text format\n",
    "interactions = ul.request.urlopen(query_url).read().decode('utf-8').splitlines()\n",
    "\n",
    "# we need to split the result by these 'tabs' (\\t - is used to identfy them)\n",
    "int_test = [interaction.split('\\t') for interaction in interactions]\n",
    "\n",
    "# we extract the field names from the first row\n",
    "column_names = int_test[:1][0]\n",
    "\n",
    "# create a Pandas dataframe of the interaction data we have just retrieved from String-DB\n",
    "interactions_df = pd.DataFrame(int_test,columns=column_names)\n",
    "\n",
    "# delete the first row that held the fieldnames but we no longer need\n",
    "interactions_df = interactions_df.drop(labels=0,axis=0)\n",
    "\n",
    "# remove any duplicate rows\n",
    "final_interactions = interactions_df.drop_duplicates()\n",
    "\n",
    "# show the top of the protein-protein interaction table\n",
    "final_interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 2.3\n",
    "# check which genes are missing from the interaction table\n",
    "\n",
    "# find the unique gene symbols in the interaction table\n",
    "unique_genes = set(final_interactions['preferredName_A']) | set(final_interactions['preferredName_B'])\n",
    "\n",
    "# compare to the gene symbols in the pathway\n",
    "missing_genes = set(gene_symbols) - set(unique_genes)\n",
    "\n",
    "# print the missing genes\n",
    "print('The following genes are missing from the interaction table and are therefore orphans:')\n",
    "print(missing_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 2.4\n",
    "# create a network from the interaction table\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# add the nodes to the graph\n",
    "G.add_nodes_from(unique_genes)\n",
    "\n",
    "# add the edges to the graph\n",
    "G.add_edges_from(final_interactions[['preferredName_A','preferredName_B']].to_numpy())\n",
    "\n",
    "# how many edges and nodes in the graph?\n",
    "print('The graph has '+str(G.number_of_edges())+' edges and '+str(G.number_of_nodes())+' nodes.')\n",
    "\n",
    "# divide the number of edges by the number of nodes to get the average degree\n",
    "print('The average degree of the graph is '+str(G.number_of_edges()/G.number_of_nodes())+'.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 2.5\n",
    "\n",
    "# query string again but restrict to only experimentally determined interactions\n",
    "query_url = 'https://string-db.org/api/tsv/network?identifiers='+stringdbIDs+'&species=9606'\n",
    "\n",
    "# again using urllib to retrieve the interactions these are returned in a standard tab delimied text format\n",
    "interactions = ul.request.urlopen(query_url).read().decode('utf-8').splitlines()\n",
    "\n",
    "# we need to split the result by these 'tabs' (\\t - is used to identfy them)\n",
    "int_test = [interaction.split('\\t') for interaction in interactions]\n",
    "\n",
    "# we extract the field names from the first row\n",
    "column_names = int_test[:1][0]\n",
    "\n",
    "# create a Pandas dataframe of the interaction data we have just retrieved from String-DB\n",
    "interactions_df = pd.DataFrame(int_test,columns=column_names)\n",
    "\n",
    "# delete the first row that held the fieldnames but we no longer need\n",
    "interactions_df = interactions_df.drop(labels=0,axis=0)\n",
    "\n",
    "# remove any duplicate rows\n",
    "final_interactions = interactions_df.drop_duplicates()\n",
    "\n",
    "final_interactions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# restrict to experimentally determined interactions by filtering on the 'escore' column > 0\n",
    "final_interactions['escore'] = pd.to_numeric(final_interactions['escore'])\n",
    "\n",
    "# filter the dataframe to only include interactions with an escore > 0\n",
    "final_interactions_experimental = final_interactions[final_interactions['escore'] > 0]\n",
    "\n",
    "# check which genes are missing from the interaction table\n",
    "\n",
    "# find the unique gene symbols in the interaction table\n",
    "unique_genes = set(final_interactions_experimental['preferredName_A']) | set(final_interactions_experimental['preferredName_B'])\n",
    "\n",
    "# compare to the gene symbols in the pathway\n",
    "missing_genes = set(gene_symbols) - set(unique_genes)\n",
    "\n",
    "# print the missing genes\n",
    "print('There are '+str(len(missing_genes))+' missing genes')\n",
    "print('The following genes are missing from the interaction table and are therefore orphans:')\n",
    "print(missing_genes)\n",
    "\n",
    "# create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# add the nodes to the graph\n",
    "G.add_nodes_from(unique_genes)\n",
    "\n",
    "# add the edges to the graph\n",
    "G.add_edges_from(final_interactions_experimental[['preferredName_A','preferredName_B']].to_numpy())\n",
    "\n",
    "# how many edges and nodes in the graph?\n",
    "print('The graph has '+str(G.number_of_edges())+' edges and '+str(G.number_of_nodes())+' nodes.')\n",
    "\n",
    "# divide the number of edges by the number of nodes to get the average degree\n",
    "print('The average degree of the graph is '+str(G.number_of_edges()/G.number_of_nodes())+'.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='darkblue'>Activity 3 - Gene Ontologies</font>\n",
    "\n",
    "Refer to the [bio1_week5&6_part3.ipynb](https://github.com/tisimpson/bioinformatics1/blob/main/labs/notebooks/bio1_week5%266_part3.ipynb) notebook for this activity.\n",
    "\n",
    "1. Using the same list of genes as used in the Protein-Protein interaction example above first download the [gene2GO.gz](https://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2go.gz) file that contains mappings between the genes (NB that in effect we are treating genes and proteins as the same here, but remember that technically genes can code for more than one protein isoform and the different isoforms could well have slightly different functions).\n",
    "\n",
    "We will be learning a lot more about ontologies next week, but you can find out more about the Gene Ontology [here](http://geneontology.org).\n",
    "\n",
    "2. This file contains ALL gene->gene-ontology-term mappings for all species so you need to restrict this to mappings for human genes only.\n",
    "3. Map the genes from the protein-protein interaction list to the identifier in the gene2go file to identify all of the GO annotations for each gene. Note that you will need to create a unique list of proteins in the protein-protein interaction list so:\n",
    "    - A-B, A-C, A-D (interactions) becomes A, B, C, D to look for mappings.\n",
    "4. What is the most common annotation for genes in the list?\n",
    "5. How many times is that most frequent annotated term found amongst all genes in the human genome?\n",
    "6. Is that term found more times than you would expect in the set of genes from the protein-protein interaction data? Why am I asking this!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 3.1-3.6\n",
    "\n",
    "# The solutions are in the notebbok `bio1_week5&6_part3.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='darkblue'>Activity 4 – Searching PubMed</font>\n",
    "\n",
    "Refer to the [bio1_week5&6_part4.ipynb](https://github.com/tisimpson/bioinformatics1/blob/main/labs/notebooks/bio1_week5%266_part4.ipynb) notebook for this activity.\n",
    "\n",
    "Practice using [search field tags](https://pubmed.ncbi.nlm.nih.gov/help/#using-search-field-tags) including MeSH limits to explore some of these questions at [NCBI PubMed](https://pubmed.ncbi.nlm.nih.gov)\n",
    "1. Plot a graph of how many papers were in PubMed in each year for the last 10 years\n",
    "2. How many papers are there relating to Cadherin-7 and human disease? what diseases are mentioned?\n",
    "    - Try three different search strategies, which one do you think is best and why?\n",
    "3. Can you use PubMed to work out how the emerging popularity of single-cell RNA sequencing to measure gene expression over the last 10 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 4.1-4.3\n",
    "\n",
    "# The solutions are in the notebook `bio1_week5&6_part4.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c79478e135452d4f8dcea3898ce85a4457be8d06848dc07bbec8d2854f4ceed7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
